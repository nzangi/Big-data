{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NQsAWzw0Dweu"
   },
   "source": [
    "**Importing the PyTorch Library**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "aUfwr0TgD0sX"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wTbd6jj3DvG-"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "2xNXOT8JD9jH"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets,transforms\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i16jnPw6F20p"
   },
   "source": [
    "**Read the required Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "SwJZgeoqF8iP"
   },
   "outputs": [],
   "source": [
    "trainData = pd.read_csv('trainLabels.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N3CcjEEiEuS_"
   },
   "source": [
    "**Analyzing the data with PyTorch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "id": "NhHGqMoQEq5R",
    "outputId": "feb5427d-d58e-4c8b-9d9c-65f95c1c094c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of points: 50000\n",
      "Number of features: 2\n",
      "Features: ['id' 'label']\n",
      "Number of Unique Values\n",
      "id : 50000\n",
      "label : 10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 864x576 with 0 Axes>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 864x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Number of points:\",trainData.shape[0])\n",
    "print(\"Number of features:\",trainData.shape[1])\n",
    "print(\"Features:\",trainData.columns.values)\n",
    "print(\"Number of Unique Values\")\n",
    "for col in trainData:\n",
    "    print(col,\":\",len(trainData[col].unique()))\n",
    "plt.figure(figsize=(12,8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6C6_LesvIS57"
   },
   "source": [
    "**Getting the validation set using PyTorch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F4ONa6SzIAKt",
    "outputId": "526fc3a8-7025-4019-d145-aad5183322e0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45000, 5000)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import random_split\n",
    "val_size = 5000\n",
    "train_size = len(trainData) - val_size\n",
    "\n",
    "train_ds, val_ds = random_split(trainData, [train_size, val_size])\n",
    "len(train_ds), len(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4BbJHv0kI0I5",
    "outputId": "a35fce03-2472-461c-fb2a-abe8c9f91a8d"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data.dataloader import DataLoader\n",
    "\n",
    "batch_size=64\n",
    "train_dl = DataLoader(train_ds, batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "val_dl = DataLoader(val_ds, batch_size, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9aawrMf9JSO7"
   },
   "source": [
    "**Defining the required functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "wvQgVNYqI9Qb"
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def accuracy(outputs, labels):\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n",
    "\n",
    "class ImageClassificationBase(nn.Module):\n",
    "    def training_step(self, batch):\n",
    "        images, labels = batch \n",
    "        out = self(images)                  # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels) # Calculate loss\n",
    "        accu = accuracy(out,labels)\n",
    "        return loss,accu\n",
    "    \n",
    "    def validation_step(self, batch):\n",
    "        images, labels = batch \n",
    "        out = self(images)                    # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels)   # Calculate loss\n",
    "        acc = accuracy(out, labels)           # Calculate accuracy\n",
    "        return {'Loss': loss.detach(), 'Accuracy': acc}\n",
    "        \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses = [x['Loss'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
    "        batch_accs = [x['Accuracy'] for x in outputs]\n",
    "        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n",
    "        return {'Loss': epoch_loss.item(), 'Accuracy': epoch_acc.item()}\n",
    "    \n",
    "    def epoch_end(self, epoch, result):\n",
    "        print(\"Epoch :\",epoch + 1)\n",
    "        print(f'Train Accuracy:{result[\"train_accuracy\"]*100:.2f}% Validation Accuracy:{result[\"Accuracy\"]*100:.2f}%')\n",
    "        print(f'Train Loss:{result[\"train_loss\"]:.4f} Validation Loss:{result[\"Loss\"]:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "global file_name1\n",
    "file_name1='model.pth'\n",
    "model_folder_path = './model'\n",
    "if not os.path.exists(model_folder_path):\n",
    "    os.makedirs(model_folder_path)\n",
    "file_name = os.path.join(model_folder_path,file_name1)\n",
    "#         torch.save(self.state_dict(), file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nLl6gEgvJ1T1"
   },
   "source": [
    "**Implementation of convolutional neural network module**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "UyLbBtozJxqe"
   },
   "outputs": [],
   "source": [
    "class Cifar10CnnModel(ImageClassificationBase):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2), # output: 64 x 16 x 16\n",
    "            nn.BatchNorm2d(64),\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2), # output: 128 x 8 x 8\n",
    "            nn.BatchNorm2d(128),\n",
    "\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2), # output: 256 x 4 x 4\n",
    "            nn.BatchNorm2d(256),\n",
    "\n",
    "            nn.Flatten(), \n",
    "            nn.Linear(256*4*4, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10))\n",
    "        \n",
    "    def forward(self, xb):\n",
    "        return self.network(xb)\n",
    "#     Train the model\n",
    "#     @torch.no_grad()\n",
    "    def evaluate(model, data_loader):\n",
    "        model.eval()\n",
    "        outputs = [model.validation_step(batch) for batch in data_loader]\n",
    "        return model.validation_epoch_end(outputs)\n",
    "\n",
    "    def fit(model, train_loader, val_loader,epochs=10,learning_rate=0.001):\n",
    "        best_valid = None\n",
    "        history = []\n",
    "\n",
    "        optimizer = torch.optim.Adam(model.parameters(), learning_rate,weight_decay=0.0005)\n",
    "        for epoch in range(epochs):\n",
    "            # Training Phase \n",
    "            model.train()\n",
    "            train_losses = []\n",
    "            train_accuracy = []\n",
    "            for batch in tqdm(train_loader):\n",
    "                loss,accu = model.training_step(batch)\n",
    "                train_losses.append(loss)\n",
    "                train_accuracy.append(accu)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "            # Validation phase\n",
    "            result = evaluate(model, val_loader)\n",
    "            result['train_loss'] = torch.stack(train_losses).mean().item()\n",
    "            result['train_accuracy'] = torch.stack(train_accuracy).mean().item()\n",
    "            model.epoch_end(epoch, result)\n",
    "            print(\"Model saved\")\n",
    "\n",
    "            if(best_valid == None or best_valid<result['Accuracy']):\n",
    "                best_valid=result['Accuracy']\n",
    "                torch.save(model.state_dict(),file_name1)\n",
    "                print(\"Model saved\")\n",
    "    #             torch.save(model.state_dict(), 'm')\n",
    "            history.append(result)\n",
    "        return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jdpB_YF-RDt-",
    "outputId": "a43ca6ee-6f8c-4afd-debe-d60581332b71"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global file_name  \n",
    "# file_name='model.pth'\n",
    "# model_folder_path = './model'\n",
    "# if not os.path.exists(model_folder_path):\n",
    "#     os.makedirs(model_folder_path)\n",
    "# file_name = os.path.join(model_folder_path, file_name)\n",
    "# #         torch.save(self.state_dict(), file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PnSPEGmFKWQk"
   },
   "source": [
    "**Train the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "OrxofU0iJ60y"
   },
   "outputs": [],
   "source": [
    "# @torch.no_grad()\n",
    "# def evaluate(model, data_loader):\n",
    "#     model.eval()\n",
    "#     outputs = [model.validation_step(batch) for batch in data_loader]\n",
    "#     return model.validation_epoch_end(outputs)\n",
    "\n",
    "# def fit(model, train_loader, val_loader,epochs=10,learning_rate=0.001):\n",
    "#     best_valid = None\n",
    "#     history = []\n",
    "  \n",
    "#     optimizer = torch.optim.Adam(model.parameters(), learning_rate,weight_decay=0.0005)\n",
    "#     for epoch in range(epochs):\n",
    "#         # Training Phase \n",
    "#         model.train()\n",
    "#         train_losses = []\n",
    "#         train_accuracy = []\n",
    "#         for batch in tqdm(train_loader):\n",
    "#             loss,accu = model.training_step(batch)\n",
    "#             train_losses.append(loss)\n",
    "#             train_accuracy.append(accu)\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "#             optimizer.zero_grad()\n",
    "#         # Validation phase\n",
    "#         result = evaluate(model, val_loader)\n",
    "#         result['train_loss'] = torch.stack(train_losses).mean().item()\n",
    "#         result['train_accuracy'] = torch.stack(train_accuracy).mean().item()\n",
    "#         model.epoch_end(epoch, result)\n",
    "#         print(\"Model saved\")\n",
    "#         global file_name\n",
    "    \n",
    "\n",
    "#         if(best_valid == None or best_valid<result['Accuracy']):\n",
    "#             best_valid=result['Accuracy']\n",
    "#             torch.save(model.state_dict(),file_name)\n",
    "#             print(\"Model saved\")\n",
    "# #             torch.save(model.state_dict(), 'm')\n",
    "#         history.append(result)\n",
    "#     return history,filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 382
    },
    "id": "n5ByDiz3KqqS",
    "outputId": "4923fd3b-e714-4135-aae8-c11dafdb942d"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'model.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# model = torch.load('model_cnn.pth')\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# model_save_name = 'model_cnn.pth'\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m model\u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_name1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m history \u001b[38;5;241m=\u001b[39m fit(model, train_dl, val_dl)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/serialization.py:584\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    581\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sys\u001b[38;5;241m.\u001b[39mversion_info \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    582\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 584\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m    586\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m _open_zipfile_reader(f) \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/serialization.py:234\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 234\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    236\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/serialization.py:215\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[0;32m--> 215\u001b[0m     \u001b[38;5;28msuper\u001b[39m(_open_file, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'model.pth'"
     ]
    }
   ],
   "source": [
    "# model = torch.load('model_cnn.pth')\n",
    "# model_save_name = 'model_cnn.pth'\n",
    "model= torch.load(file_name1)\n",
    "history = fit(model, train_dl, val_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M8UCOETuZ3S1"
   },
   "source": [
    "**Plotting the results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z0-x3AnZZ5H3"
   },
   "outputs": [],
   "source": [
    "def plot_accuracies(history):\n",
    "    Validation_accuracies = [x['Accuracy'] for x in history]\n",
    "    Training_Accuracies = [x['train_accuracy'] for x in history]\n",
    "    plt.plot(Training_Accuracies, '-rx')\n",
    "    plt.plot(Validation_accuracies, '-bx')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.legend(['Training', 'Validation'])\n",
    "    plt.title('Accuracy vs. No. of epochs');\n",
    "plot_accuracies(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IuCDfvKvZ-Iy"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_inss9_iaB--"
   },
   "outputs": [],
   "source": [
    "def plot_losses(history):\n",
    "    train_losses = [x.get('train_loss') for x in history]\n",
    "    val_losses = [x['Loss'] for x in history]\n",
    "    plt.plot(train_losses, '-bx')\n",
    "    plt.plot(val_losses, '-rx')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.legend(['Training', 'Validation'])\n",
    "    plt.title('Loss vs. No. of epochs');\n",
    "plot_losses(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rS26rQl_aFnQ"
   },
   "source": [
    "**Getting the accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V1XmSjnGafJ0"
   },
   "outputs": [],
   "source": [
    "test_dataset = ImageFolder(data_dir+'/test', transform=ToTensor())\n",
    "test_loader = DeviceDataLoader(DataLoader(test_dataset, batch_size), device)\n",
    "result = evaluate(final_model, test_loader)\n",
    "print(f'Test Accuracy:{result[\"Accuracy\"]*100:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
